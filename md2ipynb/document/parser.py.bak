# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements. See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership. The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License. You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied. See the License for the
# specific language governing permissions and limitations
# under the License.

import sys
from typing import Callable
from typing import Dict
from typing import Iterable
from typing import Iterator
from typing import Optional
from typing import Tuple
from typing import Type

from .component import Component
from .document import Document
from .paragraph import Paragraph
from .paragraph import ParagraphElement
from .section import SectionElement
from .text import Text
from .text_style import TextStyle
from .token import Token
from .token import TokenType
from .tokenizer import Tokenizer

_HEADER_TYPE_TO_STYLE = {
    TokenType.H1: TextStyle.h1,
    TokenType.H2: TextStyle.h2,
    TokenType.H3: TextStyle.h3,
    TokenType.H4: TextStyle.h4,
    TokenType.H5: TextStyle.h5,
    TokenType.H6: TextStyle.h6,
}


class Parser:
    @staticmethod
    def with_lookahead(iterable: Iterable[Token]) -> Iterator[Tuple[Token, Token]]:
        it = iter(iterable)
        previous = next(it)
        current = previous
        while not previous.is_eof():
            current = next(it)
            yield previous, current
            previous = current
        yield current, current

    def parse(self, source: Iterable[str], source_name: str = '<inputs>') -> Document:
        self._init_parser(source, source_name)
        return self._parse_document()

    def parse_file(self, filename: str) -> Document:
        with open(filename) as f:
            return self.parse(f, filename)

    # Parser helper methods.
    def _init_parser(self, source: Iterable[str], source_name: str = '<inputs>') -> None:
        self.source_name = source_name
        self.token = Token.EOF()
        self.last_token = self.token
        self.next_token = self.token
        self.tokens = self.with_lookahead(Tokenizer().tokenize(source))
        self._next()

    def _next(self) -> Token:
        self.last_token = self.token
        self.token, self.next_token = next(self.tokens)
        return self.last_token

    def _expect(self, token_type: TokenType) -> Token:
        if self.token.type != token_type:
            raise self._syntax_error(
                f"got {repr(self.token.text)} <{self.token.type}>, "
                f"expected <{token_type}>")
        return self._next()

    def _expect_any(self, token_types: Iterable[TokenType], caller: str) -> Token:
        if self.token.type not in token_types:
            valid_tokens = ', '.join(f"<{t}>" for t in token_types)
            raise self._syntax_error(
                f"{caller}: got {repr(self.token.text)} <{self.token.type}>, "
                f"expected any of {valid_tokens}")
        return self._next()

    def _line_ended(self) -> bool:
        return self.token.is_eof() or self.last_token.row <= self.token.row - 1

    def _paragraph_ended(self) -> bool:
        return self.token.is_eof() or self.last_token.row <= self.token.row - 2

    # Subparsers for different elements.
    def _parse_paragraph_element(self, caller: str) -> ParagraphElement:
        token = self._next()
        return Text(token.text)

    def _parse_paragraph(self) -> Paragraph:
        elements = []
        while not self.token.is_eof():
            elements.append(self._parse_paragraph_element('paragraph'))
            if self._paragraph_ended():
                break
        return Paragraph(elements)

    def _parse_header(self) -> Paragraph:
        elements = []
        header_token = self._expect_any(Token.list_header_types(), 'header')
        while not self.token.is_eof():
            elements.append(self._parse_paragraph_element('header'))
            if self._line_ended():
                break
        style = _HEADER_TYPE_TO_STYLE.get(header_token.type, TextStyle.body1)
        return Paragraph(elements, style=style)

    def _parse_section_element(self, caller: str) -> SectionElement:
        if self.token.is_header():
            return self._parse_header()
        return self._parse_paragraph()

    def _parse_document(self) -> Document:
        elements = []
        while not self.token.is_eof():
            elements.append(self._parse_section_element('document'))
        return Document(elements)

    # Error reporting.
    def _syntax_error(self, message: str) -> Exception:
        return self._error(SyntaxError, message)

    def _error(self, exception: Type[Exception], message: str) -> Exception:
        token = self.last_token
        msg = f"{self.source_name}:{token.row}:{token.col}: {message}"
        if token.line:
            msg += (
                f"\n\n{token.line}\n"
                f"{' '*(token.col-1)}^{'~'*(len(token.text)-1)}\n")
        return exception(msg)
